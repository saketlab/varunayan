{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5 Data Processing and Microsoft Aurora Weather Prediction for Maharashtra, India\n",
    "\n",
    "This notebook demonstrates the complete workflow of:\n",
    "1. Using the `eranest` package to download ERA5 data for Maharashtra, India\n",
    "2. Processing the data into Aurora-compatible format\n",
    "3. Running Microsoft Aurora weather predictions\n",
    "4. Visualizing the results\n",
    "\n",
    "## About Maharashtra\n",
    "Maharashtra is a state in western India with Mumbai as its capital. It's the second-most populous state in India and covers an area of approximately 307,713 km¬≤.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have:\n",
    "- CDS API credentials configured (see `eranest` documentation)\n",
    "- Required Python packages installed\n",
    "- Access to Microsoft Aurora model (via Hugging Face or local installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T11:26:59.987327Z",
     "iopub.status.busy": "2025-06-19T11:26:59.986667Z",
     "iopub.status.idle": "2025-06-19T11:27:01.265116Z",
     "shell.execute_reply": "2025-06-19T11:27:01.264885Z",
     "shell.execute_reply.started": "2025-06-19T11:26:59.987294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üì¶ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T11:27:04.293636Z",
     "iopub.status.busy": "2025-06-19T11:27:04.292850Z",
     "iopub.status.idle": "2025-06-19T11:27:04.440170Z",
     "shell.execute_reply": "2025-06-19T11:27:04.439933Z",
     "shell.execute_reply.started": "2025-06-19T11:27:04.293583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ eranest package imported successfully!\n",
      "üìä Available Aurora pressure levels: ['50', '100', '150', '200', '250', '300', '400', '500', '600', '700', '850', '925', '1000']\n",
      "üå°Ô∏è  Surface variables: ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure']\n",
      "üå™Ô∏è  Atmospheric variables: ['temperature', 'u_component_of_wind', 'v_component_of_wind', 'specific_humidity', 'geopotential']\n",
      "üó∫Ô∏è  Static variables: ['geopotential', 'land_sea_mask', 'soil_type']\n"
     ]
    }
   ],
   "source": [
    "# Import eranest package components\n",
    "try:\n",
    "    from eranest.core2 import (\n",
    "        era5_aurora_wrapper,\n",
    "        AURORA_PRESSURE_LEVELS,\n",
    "        SURFACE_VARIABLES,\n",
    "        ATMOSPHERIC_VARIABLES,\n",
    "        STATIC_VARIABLES\n",
    "    )\n",
    "    print(\"‚úÖ eranest package imported successfully!\")\n",
    "    print(f\"üìä Available Aurora pressure levels: {AURORA_PRESSURE_LEVELS}\")\n",
    "    print(f\"üå°Ô∏è  Surface variables: {SURFACE_VARIABLES}\")\n",
    "    print(f\"üå™Ô∏è  Atmospheric variables: {ATMOSPHERIC_VARIABLES}\")\n",
    "    print(f\"üó∫Ô∏è  Static variables: {STATIC_VARIABLES}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing eranest: {e}\")\n",
    "    print(\"Make sure eranest is installed and in your Python path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up Maharashtra Boundary Data\n",
    "\n",
    "We'll load the Maharashtra state boundary from the provided India GeoJSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T11:27:09.439704Z",
     "iopub.status.busy": "2025-06-19T11:27:09.439048Z",
     "iopub.status.idle": "2025-06-19T11:27:09.475308Z",
     "shell.execute_reply": "2025-06-19T11:27:09.474938Z",
     "shell.execute_reply.started": "2025-06-19T11:27:09.439668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó∫Ô∏è  Maharashtra GeoJSON loaded successfully!\n",
      "üìê Number of features: 1\n",
      "üè∑Ô∏è  Properties: ['state_name', 'state_code']\n"
     ]
    }
   ],
   "source": [
    "# Load Maharashtra boundary\n",
    "maharashtra_geojson_path = '../maharashtra_boundary.geojson'\n",
    "\n",
    "# Check if file exists, if not create it from the India GeoJSON\n",
    "if not os.path.exists(maharashtra_geojson_path):\n",
    "    print(\"üìç Extracting Maharashtra boundary from India GeoJSON...\")\n",
    "    \n",
    "    # Load the large India GeoJSON file\n",
    "    india_geojson_path = '/Users/saket/github/india-covid-explorer-viz/public/LGD_States_smooth_optimized.geojson'\n",
    "    \n",
    "    try:\n",
    "        with open(india_geojson_path, 'r') as f:\n",
    "            india_data = json.load(f)\n",
    "        \n",
    "        # Find Maharashtra feature\n",
    "        maharashtra_feature = None\n",
    "        for feature in india_data['features']:\n",
    "            if ('properties' in feature and \n",
    "                'state_name' in feature['properties'] and \n",
    "                feature['properties']['state_name'] == 'Maharashtra'):\n",
    "                maharashtra_feature = feature\n",
    "                break\n",
    "        \n",
    "        if maharashtra_feature:\n",
    "            # Create new GeoJSON with just Maharashtra\n",
    "            maharashtra_geojson = {\n",
    "                'type': 'FeatureCollection',\n",
    "                'features': [maharashtra_feature]\n",
    "            }\n",
    "            \n",
    "            # Save to file\n",
    "            with open(maharashtra_geojson_path, 'w') as f:\n",
    "                json.dump(maharashtra_geojson, f, indent=2)\n",
    "            \n",
    "            print(\"‚úÖ Maharashtra boundary extracted and saved!\")\n",
    "        else:\n",
    "            print(\"‚ùå Maharashtra not found in the India GeoJSON file\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå India GeoJSON file not found at: {india_geojson_path}\")\n",
    "        print(\"Using a simple bounding box for Maharashtra instead...\")\n",
    "        \n",
    "        # Create a simple bounding box for Maharashtra\n",
    "        maharashtra_bbox = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": [{\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\n",
    "                    \"state_name\": \"Maharashtra\",\n",
    "                    \"description\": \"Approximate bounding box for Maharashtra\"\n",
    "                },\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [[\n",
    "                        [72.6, 15.6],  # Southwest corner\n",
    "                        [80.9, 15.6],  # Southeast corner\n",
    "                        [80.9, 22.0],  # Northeast corner\n",
    "                        [72.6, 22.0],  # Northwest corner\n",
    "                        [72.6, 15.6]   # Close the polygon\n",
    "                    ]]\n",
    "                }\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        with open(maharashtra_geojson_path, 'w') as f:\n",
    "            json.dump(maharashtra_bbox, f, indent=2)\n",
    "        \n",
    "        print(\"‚úÖ Maharashtra bounding box created!\")\n",
    "\n",
    "# Load and display Maharashtra boundary info\n",
    "with open(maharashtra_geojson_path, 'r') as f:\n",
    "    maharashtra_data = json.load(f)\n",
    "\n",
    "print(f\"üó∫Ô∏è  Maharashtra GeoJSON loaded successfully!\")\n",
    "print(f\"üìê Number of features: {len(maharashtra_data['features'])}\")\n",
    "print(f\"üè∑Ô∏è  Properties: {list(maharashtra_data['features'][0]['properties'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure ERA5 Data Download Parameters\n",
    "\n",
    "We'll set up the parameters for downloading ERA5 data using the eranest package. This includes:\n",
    "- Date range for historical data (needed for Aurora initialization)\n",
    "- Variables selection (surface, atmospheric, and static)\n",
    "- Spatial resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T11:27:40.422817Z",
     "iopub.status.busy": "2025-06-19T11:27:40.422100Z",
     "iopub.status.idle": "2025-06-19T11:27:40.432781Z",
     "shell.execute_reply": "2025-06-19T11:27:40.431964Z",
     "shell.execute_reply.started": "2025-06-19T11:27:40.422779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  ERA5 Download Configuration:\n",
      "üìÖ Date range: 2024-01-01 to 2024-01-02\n",
      "üéØ Resolution: 0.25¬∞ (~28km)\n",
      "‚è∞ Frequency: hourly\n",
      "üå°Ô∏è  Surface variables (4): 2m_temperature, 10m_u_component_of_wind, 10m_v_component_of_wind, mean_sea_level_pressure\n",
      "üå™Ô∏è  Atmospheric variables (5): temperature, u_component_of_wind, v_component_of_wind, specific_humidity, geopotential\n",
      "üó∫Ô∏è  Static variables (3): geopotential, land_sea_mask, soil_type\n",
      "üìä Pressure levels (13): 50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, 1000 hPa\n"
     ]
    }
   ],
   "source": [
    "# Configure download parameters\n",
    "config = {\n",
    "    'request_id': 'maharashtra_aurora_demo',\n",
    "    'start_date': dt.datetime(2024, 1, 1, 0, 0),    # Start with recent data\n",
    "    'end_date': dt.datetime(2024, 1, 2, 0, 0),      # Two days for Aurora (needs current + previous)\n",
    "    'resolution': 0.25,  # 0.25 degree resolution (about 25km)\n",
    "    'frequency': 'hourly',\n",
    "    \n",
    "    # Aurora-compatible variables\n",
    "    'surface_variables': [\n",
    "        '2m_temperature',                    # 2t in Aurora\n",
    "        '10m_u_component_of_wind',          # 10u in Aurora  \n",
    "        '10m_v_component_of_wind',          # 10v in Aurora\n",
    "        'mean_sea_level_pressure'           # msl in Aurora\n",
    "    ],\n",
    "    \n",
    "    'atmospheric_variables': [\n",
    "        'temperature',                       # t in Aurora\n",
    "        'u_component_of_wind',              # u in Aurora\n",
    "        'v_component_of_wind',              # v in Aurora\n",
    "        'specific_humidity',                # q in Aurora\n",
    "        'geopotential'                      # z in Aurora\n",
    "    ],\n",
    "    \n",
    "    'static_variables': [\n",
    "        'geopotential',                     # z in Aurora (surface)\n",
    "        'land_sea_mask',                    # lsm in Aurora\n",
    "        'soil_type'                         # slt in Aurora\n",
    "    ],\n",
    "    \n",
    "    # Use Aurora standard pressure levels\n",
    "    'pressure_levels': AURORA_PRESSURE_LEVELS,\n",
    "    \n",
    "    'include_static': True\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è  ERA5 Download Configuration:\")\n",
    "print(f\"üìÖ Date range: {config['start_date'].strftime('%Y-%m-%d')} to {config['end_date'].strftime('%Y-%m-%d')}\")\n",
    "print(f\"üéØ Resolution: {config['resolution']}¬∞ (~{config['resolution']*111:.0f}km)\")\n",
    "print(f\"‚è∞ Frequency: {config['frequency']}\")\n",
    "print(f\"üå°Ô∏è  Surface variables ({len(config['surface_variables'])}): {', '.join(config['surface_variables'])}\")\n",
    "print(f\"üå™Ô∏è  Atmospheric variables ({len(config['atmospheric_variables'])}): {', '.join(config['atmospheric_variables'])}\")\n",
    "print(f\"üó∫Ô∏è  Static variables ({len(config['static_variables'])}): {', '.join(config['static_variables'])}\")\n",
    "print(f\"üìä Pressure levels ({len(config['pressure_levels'])}): {', '.join(config['pressure_levels'])} hPa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download ERA5 Data using eranest\n",
    "\n",
    "Now we'll use the eranest package to download ERA5 data for Maharashtra. The `era5_aurora_wrapper` function will handle:\n",
    "- Downloading surface-level, atmospheric, and static variables\n",
    "- Filtering data to Maharashtra boundaries\n",
    "- Formatting data for Aurora compatibility\n",
    "\n",
    "‚ö†Ô∏è **Note**: This step requires CDS API credentials and may take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T11:27:43.272198Z",
     "iopub.status.busy": "2025-06-19T11:27:43.271668Z",
     "iopub.status.idle": "2025-06-19T11:33:35.344587Z",
     "shell.execute_reply": "2025-06-19T11:33:35.343917Z",
     "shell.execute_reply.started": "2025-06-19T11:27:43.272162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Starting ERA5 data download for Maharashtra...\n",
      "This may take several minutes depending on data size and CDS queue.\n",
      "‚òï Time for a coffee break!\n",
      "\n",
      "Successfully loaded JSON file with utf-8 encoding\n",
      "Valid GeoJSON detected: ../maharashtra_boundary.geojson\n",
      "‚úì CDS API configuration is already set up and valid.\n",
      "\n",
      "======================================================================\n",
      "STARTING ERA5 AURORA DATA PROCESSING\n",
      "======================================================================\n",
      "Request ID: maharashtra_aurora_demo\n",
      "Date Range: 2024-01-01 to 2024-01-02\n",
      "Frequency: hourly\n",
      "Resolution: 0.25¬∞\n",
      "GeoJSON File: ../maharashtra_boundary.geojson\n",
      "Surface variables: ['2m_temperature', '10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure']\n",
      "Atmospheric variables: ['temperature', 'u_component_of_wind', 'v_component_of_wind', 'specific_humidity', 'geopotential']\n",
      "Static variables: ['geopotential', 'land_sea_mask', 'soil_type']\n",
      "Pressure levels: ['50', '100', '150', '200', '250', '300', '400', '500', '600', '700', '850', '925', '1000']\n",
      "\n",
      "--- Input Validation ---\n",
      "‚úì All inputs validated successfully\n",
      "\n",
      "--- Loading GeoJSON File ---\n",
      "‚úì Successfully loaded GeoJSON file\n",
      "\n",
      "--- Calculating Bounding Box ---\n",
      "‚úì Bounding Box calculated:\n",
      "  North: 22.0303¬∞, South: 15.6061¬∞\n",
      "  East: 80.8977¬∞, West: 72.6420¬∞\n",
      "\n",
      "--- Downloading Static Variables ---\n",
      "Downloading static ERA5 variables...\n",
      "Variables: geopotential, land_sea_mask, soil_type\n",
      "Area: North: 22.0303, West: 72.642, South: 15.6061, East: 80.8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 16:57:43,985 INFO [2025-06-16T00:00:00] CC-BY licence to replace Licence to use Copernicus Products on 02 July 2025. More information available [here](https://forum.ecmwf.int/t/cc-by-licence-to-replace-licence-to-use-copernicus-products-on-02-july-2025/13464)\n",
      "2025-06-19 16:57:43,987 INFO [2025-06-10T00:00:00] To improve our C3S service, we need to hear from you! Please complete this very short [survey](https://confluence.ecmwf.int/x/E7uBEQ/). Thank you.\n",
      "2025-06-19 16:57:43,988 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-06-19 16:57:44,844 INFO Request ID is 6459b89b-edb7-4b5d-9fa7-4098443c77c7\n",
      "2025-06-19 16:57:45,078 INFO status has been updated to accepted\n",
      "2025-06-19 16:57:50,559 INFO status has been updated to running\n",
      "2025-06-19 16:58:19,274 INFO status has been updated to successful\n",
      "                                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static variables download complete: maharashtra_aurora_demo_static.nc\n",
      "‚úì Static variables downloaded successfully\n",
      "\n",
      "--- Downloading Surface-Level Variables ---\n",
      "Downloading surface-level ERA5 data...\n",
      "Date range: 2024-01-01 to 2024-01-02\n",
      "Variables: 2m_temperature, 10m_u_component_of_wind, 10m_v_component_of_wind, mean_sea_level_pressure\n",
      "Area: North: 22.0303, West: 72.642, South: 15.6061, East: 80.8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 16:58:22,680 INFO [2025-06-16T00:00:00] CC-BY licence to replace Licence to use Copernicus Products on 02 July 2025. More information available [here](https://forum.ecmwf.int/t/cc-by-licence-to-replace-licence-to-use-copernicus-products-on-02-july-2025/13464)\n",
      "2025-06-19 16:58:22,681 INFO [2025-06-10T00:00:00] To improve our C3S service, we need to hear from you! Please complete this very short [survey](https://confluence.ecmwf.int/x/E7uBEQ/). Thank you.\n",
      "2025-06-19 16:58:22,681 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-06-19 16:58:23,767 INFO Request ID is a0f7f219-43ed-46cf-9fd9-efb621765a77\n",
      "2025-06-19 16:58:23,972 INFO status has been updated to accepted\n",
      "2025-06-19 16:58:33,495 INFO status has been updated to running\n",
      "2025-06-19 16:58:46,600 INFO status has been updated to successful\n",
      "                                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surface-level download complete: maharashtra_aurora_demo_surface.nc\n",
      "‚úì Surface-level variables downloaded successfully\n",
      "\n",
      "--- Downloading Atmospheric Variables ---\n",
      "Downloading atmospheric ERA5 data...\n",
      "Date range: 2024-01-01 to 2024-01-02\n",
      "Variables: temperature, u_component_of_wind, v_component_of_wind, specific_humidity, geopotential\n",
      "Pressure levels: 50, 100, 150, 200, 250, 300, 400, 500, 600, 700, 850, 925, 1000\n",
      "Area: North: 22.0303, West: 72.642, South: 15.6061, East: 80.8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-19 16:58:49,754 INFO [2025-06-16T00:00:00] CC-BY licence to replace Licence to use Copernicus Products on 02 July 2025. More information available [here](https://forum.ecmwf.int/t/cc-by-licence-to-replace-licence-to-use-copernicus-products-on-02-july-2025/13464)\n",
      "2025-06-19 16:58:49,756 INFO [2025-06-10T00:00:00] To improve our C3S service, we need to hear from you! Please complete this very short [survey](https://confluence.ecmwf.int/x/E7uBEQ/). Thank you.\n",
      "2025-06-19 16:58:49,757 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-06-19 16:58:50,263 INFO Request ID is 0e5548f3-580c-4c30-9ae8-30a28d458f51\n",
      "2025-06-19 16:58:50,490 INFO status has been updated to accepted\n",
      "2025-06-19 16:58:56,220 INFO status has been updated to running\n",
      "2025-06-19 17:03:12,391 INFO status has been updated to successful\n",
      "                                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atmospheric data download complete: maharashtra_aurora_demo_atmospheric.nc\n",
      "‚úì Atmospheric variables downloaded successfully\n",
      "\n",
      "--- Processing Downloaded Files ---\n",
      "\n",
      "‚Üí Processing static data: maharashtra_aurora_demo_static.nc\n",
      "  ‚úì Loaded dataset with dimensions: {'valid_time': 1, 'latitude': 26, 'longitude': 34}\n",
      "  ‚Üí Filtering static data by shapefile...\n",
      "Starting optimized filtering process...\n",
      "‚Üí Extracting unique lat/lon coordinates from dataset...\n",
      "‚úì Found 884 unique lat/lon combinations\n",
      "‚Üí Filtering unique coordinates against polygon...\n",
      "‚úì Coordinate filtering completed in 0.06 seconds\n",
      "  - Points inside: 428\n",
      "  - Points outside: 456\n",
      "  - Percentage inside: 48.42%\n",
      "‚Üí Filtering original dataset using inside coordinates...\n",
      "  Converting dataset to DataFrame...\n",
      "  ‚úì Converted to DataFrame with 884 rows\n",
      "  ‚úì Created lookup set with 428 coordinate pairs\n",
      "  Filtering DataFrame rows...\n",
      "  ‚úì Filtered from 884 to 428 rows\n",
      "‚úì Dataset filtering completed in 0.01 seconds\n",
      "\n",
      "--- Final Filtering Results ---\n",
      "Total processing time: 0.28 seconds\n",
      "Final DataFrame shape: (428, 8)\n",
      "Rows in final dataset: 428\n",
      "  ‚úì Filtered data shape: (428, 8)\n",
      "\n",
      "‚Üí Processing surface data: maharashtra_aurora_demo_surface.nc\n",
      "  ‚úì Loaded dataset with dimensions: {'valid_time': 48, 'latitude': 26, 'longitude': 34}\n",
      "  ‚Üí Filtering surface data by shapefile...\n",
      "Starting optimized filtering process...\n",
      "‚Üí Extracting unique lat/lon coordinates from dataset...\n",
      "‚úì Found 884 unique lat/lon combinations\n",
      "‚Üí Filtering unique coordinates against polygon...\n",
      "‚úì Coordinate filtering completed in 0.04 seconds\n",
      "  - Points inside: 428\n",
      "  - Points outside: 456\n",
      "  - Percentage inside: 48.42%\n",
      "‚Üí Filtering original dataset using inside coordinates...\n",
      "  Converting dataset to DataFrame...\n",
      "  ‚úì Converted to DataFrame with 42432 rows\n",
      "  ‚úì Created lookup set with 428 coordinate pairs\n",
      "  Filtering DataFrame rows...\n",
      "  ‚úì Filtered from 42432 to 20544 rows\n",
      "‚úì Dataset filtering completed in 0.02 seconds\n",
      "\n",
      "--- Final Filtering Results ---\n",
      "Total processing time: 0.09 seconds\n",
      "Final DataFrame shape: (20544, 9)\n",
      "Rows in final dataset: 20544\n",
      "  ‚úì Filtered data shape: (20544, 9)\n",
      "\n",
      "‚Üí Processing atmospheric data: maharashtra_aurora_demo_atmospheric.nc\n",
      "  ‚úì Loaded dataset with dimensions: {'valid_time': 48, 'pressure_level': 13, 'latitude': 26, 'longitude': 34}\n",
      "  ‚Üí Filtering atmospheric data by shapefile...\n",
      "Starting optimized filtering process...\n",
      "‚Üí Extracting unique lat/lon coordinates from dataset...\n",
      "‚úì Found 884 unique lat/lon combinations\n",
      "‚Üí Filtering unique coordinates against polygon...\n",
      "‚úì Coordinate filtering completed in 0.04 seconds\n",
      "  - Points inside: 428\n",
      "  - Points outside: 456\n",
      "  - Percentage inside: 48.42%\n",
      "‚Üí Filtering original dataset using inside coordinates...\n",
      "  Converting dataset to DataFrame...\n",
      "  ‚úì Converted to DataFrame with 551616 rows\n",
      "  ‚úì Created lookup set with 428 coordinate pairs\n",
      "  Filtering DataFrame rows...\n",
      "  ‚úì Filtered from 551616 to 267072 rows\n",
      "‚úì Dataset filtering completed in 0.26 seconds\n",
      "\n",
      "--- Final Filtering Results ---\n",
      "Total processing time: 0.33 seconds\n",
      "Final DataFrame shape: (267072, 11)\n",
      "Rows in final dataset: 267072\n",
      "  ‚úì Filtered data shape: (267072, 11)\n",
      "\n",
      "--- Saving Results ---\n",
      "‚Üí Created output directory: maharashtra_aurora_demo_aurora_output\n",
      "‚úì Static data exported to: maharashtra_aurora_demo_aurora_output/maharashtra_aurora_demo_static_hourly_data.csv\n",
      "‚úì Surface data exported to: maharashtra_aurora_demo_aurora_output/maharashtra_aurora_demo_surface_hourly_data.csv\n",
      "‚úì Atmospheric data exported to: maharashtra_aurora_demo_aurora_output/maharashtra_aurora_demo_atmospheric_hourly_data.csv\n",
      "\n",
      "======================================================================\n",
      "ERA5 AURORA DATA PROCESSING COMPLETED\n",
      "======================================================================\n",
      "Downloaded data types: ['static', 'surface', 'atmospheric']\n",
      "  Static: 428 rows, 8 columns\n",
      "  Surface: 20544 rows, 9 columns\n",
      "  Atmospheric: 267072 rows, 11 columns\n",
      "\n",
      "‚úÖ ERA5 data download completed successfully!\n",
      "üì¶ Available data types: ['static', 'surface', 'atmospheric']\n",
      "\n",
      "üìä STATIC DATA:\n",
      "   Shape: (428, 8)\n",
      "   Columns: ['valid_time', 'latitude', 'longitude', 'number', 'expver', 'z', 'lsm', 'slt']\n",
      "   No time dimension\n",
      "   Unique locations: 428\n",
      "\n",
      "üìä SURFACE DATA:\n",
      "   Shape: (20544, 9)\n",
      "   Columns: ['valid_time', 'latitude', 'longitude', 'number', 'expver', 't2m', 'u10', 'v10', 'msl']\n",
      "   No time dimension\n",
      "   Unique locations: 428\n",
      "\n",
      "üìä ATMOSPHERIC DATA:\n",
      "   Shape: (267072, 11)\n",
      "   Columns: ['valid_time', 'pressure_level', 'latitude', 'longitude', 'number', 'expver', 't', 'u', 'v', 'q', 'z']\n",
      "   No time dimension\n",
      "   Unique locations: 428\n"
     ]
    }
   ],
   "source": [
    "# Download ERA5 data for Maharashtra\n",
    "print(\"üîÑ Starting ERA5 data download for Maharashtra...\")\n",
    "print(\"This may take several minutes depending on data size and CDS queue.\")\n",
    "print(\"‚òï Time for a coffee break!\\n\")\n",
    "\n",
    "try:\n",
    "    # Use eranest to download and process ERA5 data\n",
    "    era5_data = era5_aurora_wrapper(\n",
    "        request_id=config['request_id'],\n",
    "        start_date=config['start_date'],\n",
    "        end_date=config['end_date'],\n",
    "        json_file=maharashtra_geojson_path,\n",
    "        surface_variables=config['surface_variables'],\n",
    "        atmospheric_variables=config['atmospheric_variables'],\n",
    "        static_variables=config['static_variables'],\n",
    "        pressure_levels=config['pressure_levels'],\n",
    "        resolution=config['resolution'],\n",
    "        frequency=config['frequency'],\n",
    "        include_static=config['include_static']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ ERA5 data download completed successfully!\")\n",
    "    print(f\"üì¶ Available data types: {list(era5_data.keys())}\")\n",
    "    \n",
    "    # Display data summary\n",
    "    for data_type, df in era5_data.items():\n",
    "        print(f\"\\nüìä {data_type.upper()} DATA:\")\n",
    "        print(f\"   Shape: {df.shape}\")\n",
    "        print(f\"   Columns: {list(df.columns)}\")\n",
    "        print(f\"   Date range: {df['time'].min()} to {df['time'].max()}\" if 'time' in df.columns else \"   No time dimension\")\n",
    "        print(f\"   Unique locations: {len(df[['latitude', 'longitude']].drop_duplicates())}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error downloading ERA5 data: {e}\")\n",
    "    print(\"\\nüîß Troubleshooting tips:\")\n",
    "    print(\"1. Check your CDS API credentials (~/.cdsapirc)\")\n",
    "    print(\"2. Verify internet connection\")\n",
    "    print(\"3. Check CDS service status\")\n",
    "    print(\"4. Try reducing date range or spatial coverage\")\n",
    "    \n",
    "    # For demo purposes, create mock data\n",
    "    print(\"\\nüé≠ Creating mock data for demonstration...\")\n",
    "    era5_data = create_mock_era5_data(config)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Function to create mock data for demonstration\n",
    "def create_mock_era5_data(config):\n",
    "    \"\"\"Create mock ERA5 data for demonstration purposes\"\"\"\n",
    "    np.random.seed(42)  # For reproducible results\n",
    "    \n",
    "    # Create a small grid over Maharashtra\n",
    "    lats = np.linspace(15.6, 22.0, 10)  # Maharashtra latitude range\n",
    "    lons = np.linspace(72.6, 80.9, 15)  # Maharashtra longitude range\n",
    "    times = pd.date_range(config['start_date'], config['end_date'], freq='H')\n",
    "    \n",
    "    # Create grid coordinates\n",
    "    lat_grid, lon_grid = np.meshgrid(lats, lons, indexing='ij')\n",
    "    grid_points = list(zip(lat_grid.flatten(), lon_grid.flatten()))\n",
    "    \n",
    "    mock_data = {}\n",
    "    \n",
    "    # Surface data\n",
    "    surface_data = []\n",
    "    for time in times:\n",
    "        for lat, lon in grid_points:\n",
    "            surface_data.append({\n",
    "                'time': time,\n",
    "                'latitude': lat,\n",
    "                'longitude': lon,\n",
    "                't2m': 25 + 5*np.sin(2*np.pi*(time.hour/24)) + np.random.normal(0, 2),  # Temperature\n",
    "                'u10': np.random.normal(2, 1),  # U-wind\n",
    "                'v10': np.random.normal(1, 1),  # V-wind\n",
    "                'msl': 101325 + np.random.normal(0, 100)  # Sea level pressure\n",
    "            })\n",
    "    \n",
    "    mock_data['surface'] = pd.DataFrame(surface_data)\n",
    "    \n",
    "    # Atmospheric data (simplified)\n",
    "    atmos_data = []\n",
    "    for time in times:\n",
    "        for lat, lon in grid_points:\n",
    "            for level in [850, 500, 250]:  # Simplified pressure levels\n",
    "                atmos_data.append({\n",
    "                    'time': time,\n",
    "                    'latitude': lat,\n",
    "                    'longitude': lon,\n",
    "                    'level': level,\n",
    "                    't': 20 - (1000-level)*0.006 + np.random.normal(0, 1),  # Temperature lapse\n",
    "                    'u': np.random.normal(5, 2),  # U-wind\n",
    "                    'v': np.random.normal(2, 2),  # V-wind\n",
    "                    'q': 0.01 * np.exp(-(1000-level)/200) + np.random.normal(0, 0.001),  # Humidity\n",
    "                    'z': level * 8.0 + np.random.normal(0, 10)  # Geopotential\n",
    "                })\n",
    "    \n",
    "    mock_data['atmospheric'] = pd.DataFrame(atmos_data)\n",
    "    \n",
    "    # Static data\n",
    "    static_data = []\n",
    "    for lat, lon in grid_points:\n",
    "        static_data.append({\n",
    "            'latitude': lat,\n",
    "            'longitude': lon,\n",
    "            'z': 500 + np.random.normal(0, 200),  # Surface geopotential\n",
    "            'lsm': 1.0 if np.random.rand() > 0.1 else 0.0,  # Land-sea mask (mostly land)\n",
    "            'slt': np.random.randint(1, 8)  # Soil type\n",
    "        })\n",
    "    \n",
    "    mock_data['static'] = pd.DataFrame(static_data)\n",
    "    \n",
    "    return mock_data\n",
    "\n",
    "print(\"üé≠ Mock data creation function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Exploration and Visualization\n",
    "\n",
    "Let's explore the downloaded ERA5 data and visualize key meteorological variables over Maharashtra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T11:33:35.346141Z",
     "iopub.status.busy": "2025-06-19T11:33:35.345959Z",
     "iopub.status.idle": "2025-06-19T11:33:36.414871Z",
     "shell.execute_reply": "2025-06-19T11:33:36.413858Z",
     "shell.execute_reply.started": "2025-06-19T11:33:35.346128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç EXPLORING ERA5 DATA FOR MAHARASHTRA\n",
      "==================================================\n",
      "\n",
      "üå°Ô∏è  SURFACE DATA SUMMARY:\n",
      "   üìè Shape: (20544, 9)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aurora/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._engine.get_loc(casted_key)\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müå°Ô∏è  SURFACE DATA SUMMARY:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üìè Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msurface_df.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üìÖ Time range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msurface_df[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m].min()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msurface_df[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m].max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üó∫Ô∏è  Spatial coverage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(surface_df[[\u001b[33m'\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m'\u001b[39m]].drop_duplicates())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m grid points\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üìä Variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[col\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mcol\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39msurface_df.columns\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mcol\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m[\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m'\u001b[39m]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aurora/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/aurora/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'time'"
     ]
    }
   ],
   "source": [
    "# Explore the downloaded data\n",
    "print(\"üîç EXPLORING ERA5 DATA FOR MAHARASHTRA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Assume we have data from previous cell (either real or mock)\n",
    "if 'era5_data' not in locals():\n",
    "    print(\"Creating mock data for exploration...\")\n",
    "    era5_data = create_mock_era5_data(config)\n",
    "\n",
    "# Surface data exploration\n",
    "if 'surface' in era5_data:\n",
    "    surface_df = era5_data['surface']\n",
    "    print(f\"\\nüå°Ô∏è  SURFACE DATA SUMMARY:\")\n",
    "    print(f\"   üìè Shape: {surface_df.shape}\")\n",
    "    print(f\"   üìÖ Time range: {surface_df['time'].min()} to {surface_df['time'].max()}\")\n",
    "    print(f\"   üó∫Ô∏è  Spatial coverage: {len(surface_df[['latitude', 'longitude']].drop_duplicates())} grid points\")\n",
    "    print(f\"   üìä Variables: {[col for col in surface_df.columns if col not in ['time', 'latitude', 'longitude']]}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\n   üìà SURFACE VARIABLE STATISTICS:\")\n",
    "    numeric_cols = surface_df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        if col not in ['latitude', 'longitude']:\n",
    "            mean_val = surface_df[col].mean()\n",
    "            std_val = surface_df[col].std()\n",
    "            min_val = surface_df[col].min()\n",
    "            max_val = surface_df[col].max()\n",
    "            print(f\"      {col}: {mean_val:.2f} ¬± {std_val:.2f} (range: {min_val:.2f} to {max_val:.2f})\")\n",
    "\n",
    "# Atmospheric data exploration\n",
    "if 'atmospheric' in era5_data:\n",
    "    atmos_df = era5_data['atmospheric']\n",
    "    print(f\"\\nüå™Ô∏è  ATMOSPHERIC DATA SUMMARY:\")\n",
    "    print(f\"   üìè Shape: {atmos_df.shape}\")\n",
    "    print(f\"   üìä Pressure levels: {sorted(atmos_df['level'].unique()) if 'level' in atmos_df.columns else 'Not available'}\")\n",
    "    print(f\"   üìä Variables: {[col for col in atmos_df.columns if col not in ['time', 'latitude', 'longitude', 'level']]}\")\n",
    "\n",
    "# Static data exploration\n",
    "if 'static' in era5_data:\n",
    "    static_df = era5_data['static']\n",
    "    print(f\"\\nüó∫Ô∏è  STATIC DATA SUMMARY:\")\n",
    "    print(f\"   üìè Shape: {static_df.shape}\")\n",
    "    print(f\"   üìä Variables: {[col for col in static_df.columns if col not in ['latitude', 'longitude']]}\")\n",
    "    \n",
    "    # Land-sea mask analysis\n",
    "    if 'lsm' in static_df.columns:\n",
    "        land_points = (static_df['lsm'] > 0.5).sum()\n",
    "        total_points = len(static_df)\n",
    "        print(f\"   üèûÔ∏è  Land coverage: {land_points}/{total_points} points ({land_points/total_points*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Data exploration completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-19T11:33:36.415103Z",
     "iopub.status.idle": "2025-06-19T11:33:36.415252Z",
     "shell.execute_reply": "2025-06-19T11:33:36.415184Z",
     "shell.execute_reply.started": "2025-06-19T11:33:36.415179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create visualizations of ERA5 data\n",
    "print(\"üìä Creating visualizations of ERA5 data over Maharashtra...\")\n",
    "\n",
    "# Set up the plotting environment\n",
    "plt.rcParams['figure.figsize'] = (15, 12)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Create subplots for different variables\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Assume we have surface data\n",
    "if 'surface' in era5_data:\n",
    "    surface_df = era5_data['surface']\n",
    "    \n",
    "    # Get latest time step for spatial plots\n",
    "    latest_time = surface_df['time'].max()\n",
    "    latest_data = surface_df[surface_df['time'] == latest_time].copy()\n",
    "    \n",
    "    # Temperature map\n",
    "    ax1 = plt.subplot(2, 3, 1, projection=ccrs.PlateCarree())\n",
    "    ax1.set_extent([72, 81, 15, 23], crs=ccrs.PlateCarree())\n",
    "    ax1.add_feature(cfeature.COASTLINE)\n",
    "    ax1.add_feature(cfeature.BORDERS)\n",
    "    ax1.add_feature(cfeature.STATES, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Plot temperature\n",
    "    temp_var = 't2m' if 't2m' in latest_data.columns else [col for col in latest_data.columns if 'temp' in col.lower()][0]\n",
    "    scatter = ax1.scatter(latest_data['longitude'], latest_data['latitude'], \n",
    "                         c=latest_data[temp_var], cmap='RdYlBu_r', s=30, \n",
    "                         transform=ccrs.PlateCarree())\n",
    "    ax1.set_title(f'Temperature (¬∞C)\\n{latest_time.strftime(\"%Y-%m-%d %H:%M UTC\")}', fontsize=12)\n",
    "    plt.colorbar(scatter, ax=ax1, shrink=0.7)\n",
    "    ax1.gridlines(draw_labels=True, alpha=0.3)\n",
    "    \n",
    "    # Wind map\n",
    "    ax2 = plt.subplot(2, 3, 2, projection=ccrs.PlateCarree())\n",
    "    ax2.set_extent([72, 81, 15, 23], crs=ccrs.PlateCarree())\n",
    "    ax2.add_feature(cfeature.COASTLINE)\n",
    "    ax2.add_feature(cfeature.BORDERS)\n",
    "    ax2.add_feature(cfeature.STATES, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Plot wind vectors\n",
    "    u_var = 'u10' if 'u10' in latest_data.columns else [col for col in latest_data.columns if 'u' in col.lower()][0]\n",
    "    v_var = 'v10' if 'v10' in latest_data.columns else [col for col in latest_data.columns if 'v' in col.lower()][0]\n",
    "    \n",
    "    wind_speed = np.sqrt(latest_data[u_var]**2 + latest_data[v_var]**2)\n",
    "    quiver = ax2.quiver(latest_data['longitude'], latest_data['latitude'],\n",
    "                       latest_data[u_var], latest_data[v_var],\n",
    "                       wind_speed, cmap='viridis', scale=50,\n",
    "                       transform=ccrs.PlateCarree())\n",
    "    ax2.set_title(f'Wind Vectors (m/s)\\n{latest_time.strftime(\"%Y-%m-%d %H:%M UTC\")}', fontsize=12)\n",
    "    plt.colorbar(quiver, ax=ax2, shrink=0.7, label='Wind Speed (m/s)')\n",
    "    ax2.gridlines(draw_labels=True, alpha=0.3)\n",
    "    \n",
    "    # Pressure map\n",
    "    ax3 = plt.subplot(2, 3, 3, projection=ccrs.PlateCarree())\n",
    "    ax3.set_extent([72, 81, 15, 23], crs=ccrs.PlateCarree())\n",
    "    ax3.add_feature(cfeature.COASTLINE)\n",
    "    ax3.add_feature(cfeature.BORDERS)\n",
    "    ax3.add_feature(cfeature.STATES, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Plot pressure\n",
    "    press_var = 'msl' if 'msl' in latest_data.columns else [col for col in latest_data.columns if 'press' in col.lower()][0]\n",
    "    pressure_scatter = ax3.scatter(latest_data['longitude'], latest_data['latitude'],\n",
    "                                  c=latest_data[press_var]/100, cmap='RdBu_r', s=30,  # Convert to hPa\n",
    "                                  transform=ccrs.PlateCarree())\n",
    "    ax3.set_title(f'Sea Level Pressure (hPa)\\n{latest_time.strftime(\"%Y-%m-%d %H:%M UTC\")}', fontsize=12)\n",
    "    plt.colorbar(pressure_scatter, ax=ax3, shrink=0.7)\n",
    "    ax3.gridlines(draw_labels=True, alpha=0.3)\n",
    "    \n",
    "    # Time series plot\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    \n",
    "    # Average temperature over Maharashtra\n",
    "    temp_ts = surface_df.groupby('time')[temp_var].mean()\n",
    "    ax4.plot(temp_ts.index, temp_ts.values, 'r-', linewidth=2, label='Temperature')\n",
    "    ax4.set_ylabel('Temperature (¬∞C)', color='r')\n",
    "    ax4.tick_params(axis='y', labelcolor='r')\n",
    "    ax4.set_title('Average Meteorological Variables\\nOver Maharashtra', fontsize=12)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add pressure on secondary axis\n",
    "    ax4_twin = ax4.twinx()\n",
    "    press_ts = surface_df.groupby('time')[press_var].mean()\n",
    "    ax4_twin.plot(press_ts.index, press_ts.values/100, 'b-', linewidth=2, label='Pressure')\n",
    "    ax4_twin.set_ylabel('Pressure (hPa)', color='b')\n",
    "    ax4_twin.tick_params(axis='y', labelcolor='b')\n",
    "    \n",
    "    plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    # Wind speed distribution\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    wind_speed_all = np.sqrt(surface_df[u_var]**2 + surface_df[v_var]**2)\n",
    "    ax5.hist(wind_speed_all, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "    ax5.set_xlabel('Wind Speed (m/s)')\n",
    "    ax5.set_ylabel('Frequency')\n",
    "    ax5.set_title('Wind Speed Distribution\\nOver Maharashtra', fontsize=12)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics\n",
    "    mean_wind = wind_speed_all.mean()\n",
    "    max_wind = wind_speed_all.max()\n",
    "    ax5.axvline(mean_wind, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_wind:.1f} m/s')\n",
    "    ax5.legend()\n",
    "\n",
    "# Static data visualization\n",
    "if 'static' in era5_data:\n",
    "    static_df = era5_data['static']\n",
    "    \n",
    "    ax6 = plt.subplot(2, 3, 6, projection=ccrs.PlateCarree())\n",
    "    ax6.set_extent([72, 81, 15, 23], crs=ccrs.PlateCarree())\n",
    "    ax6.add_feature(cfeature.COASTLINE)\n",
    "    ax6.add_feature(cfeature.BORDERS)\n",
    "    ax6.add_feature(cfeature.STATES, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Plot topography\n",
    "    topo_var = 'z' if 'z' in static_df.columns else [col for col in static_df.columns if col not in ['latitude', 'longitude', 'lsm', 'slt']][0]\n",
    "    topo_scatter = ax6.scatter(static_df['longitude'], static_df['latitude'],\n",
    "                              c=static_df[topo_var]/9.81, cmap='terrain', s=30,  # Convert to height\n",
    "                              transform=ccrs.PlateCarree())\n",
    "    ax6.set_title('Topography (m)\\n(Surface Geopotential Height)', fontsize=12)\n",
    "    plt.colorbar(topo_scatter, ax=ax6, shrink=0.7)\n",
    "    ax6.gridlines(draw_labels=True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('ERA5 Meteorological Data Analysis for Maharashtra, India', fontsize=16, y=0.98)\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ ERA5 data visualization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Microsoft Aurora\n",
    "\n",
    "Now we'll convert the ERA5 data into the format required by Microsoft Aurora. According to the Aurora documentation, we need to create a `Batch` object with:\n",
    "- Surface variables (2t, 10u, 10v, msl)\n",
    "- Static variables (lsm, z, slt)\n",
    "- Atmospheric variables (z, u, v, t, q) at pressure levels\n",
    "- Metadata (lat, lon, time, pressure levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-19T11:33:36.416225Z",
     "iopub.status.idle": "2025-06-19T11:33:36.416909Z",
     "shell.execute_reply": "2025-06-19T11:33:36.416527Z",
     "shell.execute_reply.started": "2025-06-19T11:33:36.416520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install Microsoft Aurora (if not already installed)\n",
    "print(\"üîß Setting up Microsoft Aurora...\")\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"‚úÖ PyTorch available\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå PyTorch not found. Installing...\")\n",
    "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "# Try to import Aurora\n",
    "try:\n",
    "    from aurora import Batch, Metadata\n",
    "    print(\"‚úÖ Microsoft Aurora imported successfully!\")\n",
    "    AURORA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  Microsoft Aurora not available. Installing from source...\")\n",
    "    AURORA_AVAILABLE = False\n",
    "    \n",
    "    # For demo purposes, we'll create mock Aurora classes\n",
    "    print(\"üé≠ Creating mock Aurora classes for demonstration...\")\n",
    "    \n",
    "    class MockMetadata:\n",
    "        def __init__(self, lat, lon, time, atmos_levels):\n",
    "            self.lat = lat\n",
    "            self.lon = lon\n",
    "            self.time = time\n",
    "            self.atmos_levels = atmos_levels\n",
    "    \n",
    "    class MockBatch:\n",
    "        def __init__(self, surf_vars, static_vars, atmos_vars, metadata):\n",
    "            self.surf_vars = surf_vars\n",
    "            self.static_vars = static_vars\n",
    "            self.atmos_vars = atmos_vars\n",
    "            self.metadata = metadata\n",
    "            \n",
    "        def __repr__(self):\n",
    "            return f\"MockBatch(surf_vars={list(self.surf_vars.keys())}, static_vars={list(self.static_vars.keys())}, atmos_vars={list(self.atmos_vars.keys())})\"\n",
    "    \n",
    "    Batch = MockBatch\n",
    "    Metadata = MockMetadata\n",
    "\n",
    "print(f\"üéØ Aurora setup complete (Available: {AURORA_AVAILABLE})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-19T11:33:36.419785Z",
     "iopub.status.idle": "2025-06-19T11:33:36.421138Z",
     "shell.execute_reply": "2025-06-19T11:33:36.421047Z",
     "shell.execute_reply.started": "2025-06-19T11:33:36.421037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert ERA5 data to Aurora format\n",
    "print(\"üîÑ Converting ERA5 data to Aurora-compatible format...\")\n",
    "\n",
    "def era5_to_aurora_batch(era5_data, config):\n",
    "    \"\"\"Convert ERA5 data to Aurora Batch format\"\"\"\n",
    "    import torch\n",
    "    from datetime import datetime\n",
    "    \n",
    "    print(\"üì¶ Processing ERA5 data for Aurora...\")\n",
    "    \n",
    "    # Get surface data\n",
    "    surface_df = era5_data.get('surface')\n",
    "    static_df = era5_data.get('static')\n",
    "    atmos_df = era5_data.get('atmospheric')\n",
    "    \n",
    "    if surface_df is None:\n",
    "        raise ValueError(\"Surface data is required for Aurora\")\n",
    "    \n",
    "    # Get unique coordinates and times\n",
    "    coords = surface_df[['latitude', 'longitude']].drop_duplicates().sort_values(['latitude', 'longitude'])\n",
    "    times = sorted(surface_df['time'].unique())\n",
    "    \n",
    "    print(f\"   üìç Grid points: {len(coords)}\")\n",
    "    print(f\"   ‚è∞ Time steps: {len(times)}\")\n",
    "    \n",
    "    # Create coordinate arrays\n",
    "    lats = torch.tensor(sorted(coords['latitude'].unique(), reverse=True), dtype=torch.float32)  # Aurora wants decreasing\n",
    "    lons = torch.tensor(sorted(coords['longitude'].unique()), dtype=torch.float32)\n",
    "    \n",
    "    h, w = len(lats), len(lons)\n",
    "    t = min(len(times), 2)  # Aurora needs current + previous step\n",
    "    b = 1  # Batch size\n",
    "    \n",
    "    print(f\"   üìê Grid dimensions: {h} x {w} (lat x lon)\")\n",
    "    print(f\"   ‚è≥ Time history: {t} steps\")\n",
    "    \n",
    "    # Initialize tensors\n",
    "    surf_vars = {}\n",
    "    static_vars = {}\n",
    "    atmos_vars = {}\n",
    "    \n",
    "    # Process surface variables\n",
    "    print(\"   üå°Ô∏è  Processing surface variables...\")\n",
    "    \n",
    "    # Variable name mapping from ERA5 to Aurora\n",
    "    surf_var_mapping = {\n",
    "        't2m': '2t',  # Temperature\n",
    "        'u10': '10u',  # U-wind\n",
    "        'v10': '10v',  # V-wind  \n",
    "        'msl': 'msl'   # Mean sea level pressure\n",
    "    }\n",
    "    \n",
    "    for era5_var, aurora_var in surf_var_mapping.items():\n",
    "        if era5_var in surface_df.columns:\n",
    "            # Create tensor (b, t, h, w)\n",
    "            var_tensor = torch.zeros(b, t, h, w, dtype=torch.float32)\n",
    "            \n",
    "            for time_idx, time_val in enumerate(times[-t:]):  # Use last t time steps\n",
    "                time_data = surface_df[surface_df['time'] == time_val]\n",
    "                \n",
    "                for _, row in time_data.iterrows():\n",
    "                    lat_idx = torch.argmin(torch.abs(lats - row['latitude']))\n",
    "                    lon_idx = torch.argmin(torch.abs(lons - row['longitude']))\n",
    "                    var_tensor[0, time_idx, lat_idx, lon_idx] = row[era5_var]\n",
    "            \n",
    "            surf_vars[aurora_var] = var_tensor\n",
    "            print(f\"      ‚úì {aurora_var}: {var_tensor.shape}\")\n",
    "    \n",
    "    # Process static variables\n",
    "    if static_df is not None:\n",
    "        print(\"   üó∫Ô∏è  Processing static variables...\")\n",
    "        \n",
    "        static_var_mapping = {\n",
    "            'z': 'z',      # Surface geopotential\n",
    "            'lsm': 'lsm',  # Land-sea mask\n",
    "            'slt': 'slt'   # Soil type\n",
    "        }\n",
    "        \n",
    "        for era5_var, aurora_var in static_var_mapping.items():\n",
    "            if era5_var in static_df.columns:\n",
    "                # Create tensor (h, w)\n",
    "                var_tensor = torch.zeros(h, w, dtype=torch.float32)\n",
    "                \n",
    "                for _, row in static_df.iterrows():\n",
    "                    lat_idx = torch.argmin(torch.abs(lats - row['latitude']))\n",
    "                    lon_idx = torch.argmin(torch.abs(lons - row['longitude']))\n",
    "                    var_tensor[lat_idx, lon_idx] = row[era5_var]\n",
    "                \n",
    "                static_vars[aurora_var] = var_tensor\n",
    "                print(f\"      ‚úì {aurora_var}: {var_tensor.shape}\")\n",
    "    \n",
    "    # Process atmospheric variables\n",
    "    if atmos_df is not None and 'level' in atmos_df.columns:\n",
    "        print(\"   üå™Ô∏è  Processing atmospheric variables...\")\n",
    "        \n",
    "        pressure_levels = sorted(atmos_df['level'].unique())\n",
    "        c = len(pressure_levels)\n",
    "        \n",
    "        atmos_var_mapping = {\n",
    "            't': 't',    # Temperature\n",
    "            'u': 'u',    # U-wind\n",
    "            'v': 'v',    # V-wind\n",
    "            'q': 'q',    # Specific humidity\n",
    "            'z': 'z'     # Geopotential\n",
    "        }\n",
    "        \n",
    "        for era5_var, aurora_var in atmos_var_mapping.items():\n",
    "            if era5_var in atmos_df.columns:\n",
    "                # Create tensor (b, t, c, h, w)\n",
    "                var_tensor = torch.zeros(b, t, c, h, w, dtype=torch.float32)\n",
    "                \n",
    "                for time_idx, time_val in enumerate(times[-t:]):\n",
    "                    time_data = atmos_df[atmos_df['time'] == time_val]\n",
    "                    \n",
    "                    for level_idx, level in enumerate(pressure_levels):\n",
    "                        level_data = time_data[time_data['level'] == level]\n",
    "                        \n",
    "                        for _, row in level_data.iterrows():\n",
    "                            lat_idx = torch.argmin(torch.abs(lats - row['latitude']))\n",
    "                            lon_idx = torch.argmin(torch.abs(lons - row['longitude']))\n",
    "                            var_tensor[0, time_idx, level_idx, lat_idx, lon_idx] = row[era5_var]\n",
    "                \n",
    "                atmos_vars[aurora_var] = var_tensor\n",
    "                print(f\"      ‚úì {aurora_var}: {var_tensor.shape}\")\n",
    "    \n",
    "    # Create metadata\n",
    "    pressure_levels_hpa = tuple(pressure_levels) if 'atmos_df' in locals() and atmos_df is not None else (850, 500, 250)\n",
    "    current_time = times[-1] if times else datetime(2024, 1, 1, 12, 0)\n",
    "    \n",
    "    metadata = Metadata(\n",
    "        lat=lats,\n",
    "        lon=lons,\n",
    "        time=(current_time,),\n",
    "        atmos_levels=pressure_levels_hpa\n",
    "    )\n",
    "    \n",
    "    # Create Aurora batch\n",
    "    aurora_batch = Batch(\n",
    "        surf_vars=surf_vars,\n",
    "        static_vars=static_vars,\n",
    "        atmos_vars=atmos_vars,\n",
    "        metadata=metadata\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Aurora batch created successfully!\")\n",
    "    print(f\"   üì¶ Surface variables: {list(surf_vars.keys())}\")\n",
    "    print(f\"   üó∫Ô∏è  Static variables: {list(static_vars.keys())}\")\n",
    "    print(f\"   üå™Ô∏è  Atmospheric variables: {list(atmos_vars.keys())}\")\n",
    "    print(f\"   üìä Pressure levels: {pressure_levels_hpa}\")\n",
    "    print(f\"   üìÖ Current time: {current_time}\")\n",
    "    \n",
    "    return aurora_batch\n",
    "\n",
    "# Convert data to Aurora format\n",
    "try:\n",
    "    aurora_batch = era5_to_aurora_batch(era5_data, config)\n",
    "    print(f\"\\nüéØ Aurora batch ready: {aurora_batch}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating Aurora batch: {e}\")\n",
    "    print(\"Creating a minimal mock batch for demonstration...\")\n",
    "    \n",
    "    # Create mock tensors for demonstration\n",
    "    import torch\n",
    "    aurora_batch = Batch(\n",
    "        surf_vars={'2t': torch.randn(1, 2, 10, 15), '10u': torch.randn(1, 2, 10, 15), \n",
    "                  '10v': torch.randn(1, 2, 10, 15), 'msl': torch.randn(1, 2, 10, 15)},\n",
    "        static_vars={'lsm': torch.randn(10, 15), 'z': torch.randn(10, 15), 'slt': torch.randn(10, 15)},\n",
    "        atmos_vars={'t': torch.randn(1, 2, 3, 10, 15), 'u': torch.randn(1, 2, 3, 10, 15),\n",
    "                   'v': torch.randn(1, 2, 3, 10, 15), 'q': torch.randn(1, 2, 3, 10, 15),\n",
    "                   'z': torch.randn(1, 2, 3, 10, 15)},\n",
    "        metadata=Metadata(\n",
    "            lat=torch.linspace(22.0, 15.6, 10),\n",
    "            lon=torch.linspace(72.6, 80.9, 15),\n",
    "            time=(dt.datetime(2024, 1, 1, 12, 0),),\n",
    "            atmos_levels=(850, 500, 250)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load and Run Microsoft Aurora Model\n",
    "\n",
    "Now we'll load the Microsoft Aurora model and use it to generate weather predictions for Maharashtra. Aurora can predict weather conditions up to 10 days in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-19T11:33:36.422846Z",
     "iopub.status.idle": "2025-06-19T11:33:36.423211Z",
     "shell.execute_reply": "2025-06-19T11:33:36.423057Z",
     "shell.execute_reply.started": "2025-06-19T11:33:36.423047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Microsoft Aurora model\n",
    "print(\"ü§ñ Loading Microsoft Aurora weather prediction model...\")\n",
    "\n",
    "def load_aurora_model():\n",
    "    \"\"\"Load Microsoft Aurora model\"\"\"\n",
    "    if AURORA_AVAILABLE:\n",
    "        try:\n",
    "            # Try to load Aurora model from Hugging Face\n",
    "            from aurora import Aurora\n",
    "            \n",
    "            print(\"   üì• Downloading Aurora model from Hugging Face...\")\n",
    "            model = Aurora(use_lora=False)  # Use full model, not LoRA\n",
    "            model.eval()  # Set to evaluation mode\n",
    "            \n",
    "            print(\"   ‚úÖ Aurora model loaded successfully!\")\n",
    "            return model, True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Error loading real Aurora model: {e}\")\n",
    "            print(\"   üé≠ Creating mock model for demonstration...\")\n",
    "            return create_mock_aurora_model(), False\n",
    "    else:\n",
    "        print(\"   üé≠ Aurora not available, creating mock model...\")\n",
    "        return create_mock_aurora_model(), False\n",
    "\n",
    "def create_mock_aurora_model():\n",
    "    \"\"\"Create a mock Aurora model for demonstration\"\"\"\n",
    "    class MockAurora:\n",
    "        def __init__(self):\n",
    "            self.name = \"Mock Aurora Model\"\n",
    "        \n",
    "        def forward(self, batch):\n",
    "            \"\"\"Mock forward pass that returns modified input\"\"\"\n",
    "            import torch\n",
    "            import copy\n",
    "            \n",
    "            # Create a mock prediction by modifying the input slightly\n",
    "            pred_batch = copy.deepcopy(batch)\n",
    "            \n",
    "            # Modify surface variables (simulate prediction)\n",
    "            for var_name, tensor in pred_batch.surf_vars.items():\n",
    "                # Remove history dimension (Aurora output has t=1)\n",
    "                if tensor.dim() == 4:  # (b, t, h, w)\n",
    "                    # Take last time step and add some random variation\n",
    "                    last_step = tensor[:, -1:, :, :].clone()\n",
    "                    \n",
    "                    if var_name == '2t':  # Temperature - add small daily cycle\n",
    "                        pred_batch.surf_vars[var_name] = last_step + torch.randn_like(last_step) * 0.5\n",
    "                    elif var_name in ['10u', '10v']:  # Wind - add variability\n",
    "                        pred_batch.surf_vars[var_name] = last_step + torch.randn_like(last_step) * 0.2\n",
    "                    elif var_name == 'msl':  # Pressure - small changes\n",
    "                        pred_batch.surf_vars[var_name] = last_step + torch.randn_like(last_step) * 50\n",
    "                    else:\n",
    "                        pred_batch.surf_vars[var_name] = last_step + torch.randn_like(last_step) * 0.1\n",
    "            \n",
    "            # Modify atmospheric variables\n",
    "            for var_name, tensor in pred_batch.atmos_vars.items():\n",
    "                if tensor.dim() == 5:  # (b, t, c, h, w)\n",
    "                    last_step = tensor[:, -1:, :, :, :].clone()\n",
    "                    pred_batch.atmos_vars[var_name] = last_step + torch.randn_like(last_step) * 0.1\n",
    "            \n",
    "            # Update metadata time (6 hours ahead)\n",
    "            import datetime as dt\n",
    "            current_time = pred_batch.metadata.time[0]\n",
    "            next_time = current_time + dt.timedelta(hours=6)\n",
    "            pred_batch.metadata.time = (next_time,)\n",
    "            \n",
    "            return pred_batch\n",
    "        \n",
    "        def __call__(self, batch):\n",
    "            return self.forward(batch)\n",
    "    \n",
    "    return MockAurora()\n",
    "\n",
    "# Load the model\n",
    "aurora_model, is_real_model = load_aurora_model()\n",
    "\n",
    "print(f\"\\nüéØ Model Status:\")\n",
    "print(f\"   Model Type: {'Real Aurora' if is_real_model else 'Mock Demo'}\")\n",
    "print(f\"   Ready for Predictions: ‚úÖ\")\n",
    "\n",
    "if not is_real_model:\n",
    "    print(f\"\\nüìù Note: Using mock model for demonstration.\")\n",
    "    print(f\"   To use real Aurora model, install from:\")\n",
    "    print(f\"   https://github.com/microsoft/aurora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-19T11:33:36.424169Z",
     "iopub.status.idle": "2025-06-19T11:33:36.424597Z",
     "shell.execute_reply": "2025-06-19T11:33:36.424385Z",
     "shell.execute_reply.started": "2025-06-19T11:33:36.424376Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate weather predictions using Aurora\n",
    "print(\"üîÆ Generating weather predictions for Maharashtra...\")\n",
    "\n",
    "def generate_predictions(model, initial_batch, num_steps=4):\n",
    "    \"\"\"Generate multiple time step predictions\"\"\"\n",
    "    predictions = []\n",
    "    current_batch = initial_batch\n",
    "    \n",
    "    print(f\"   üéØ Generating {num_steps} prediction steps (6-hour intervals)\")\n",
    "    print(f\"   ‚è∞ Starting from: {current_batch.metadata.time[0]}\")\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        print(f\"      Step {step + 1}/{num_steps}...\", end=\" \")\n",
    "        \n",
    "        # Generate prediction\n",
    "        with torch.no_grad():  # No gradients needed for inference\n",
    "            pred_batch = model(current_batch)\n",
    "        \n",
    "        predictions.append(pred_batch)\n",
    "        \n",
    "        # For next iteration, use prediction as input\n",
    "        # Aurora needs current + previous, so we combine them\n",
    "        if hasattr(pred_batch, 'surf_vars') and hasattr(current_batch, 'surf_vars'):\n",
    "            # Create new batch with prediction as current and old current as previous\n",
    "            new_surf_vars = {}\n",
    "            for var_name in pred_batch.surf_vars.keys():\n",
    "                if var_name in current_batch.surf_vars:\n",
    "                    # Combine: [previous, current] -> [old_current, prediction]\n",
    "                    old_current = current_batch.surf_vars[var_name][:, -1:, :, :]  # Last time step\n",
    "                    new_prediction = pred_batch.surf_vars[var_name]  # Should be shape (b, 1, h, w)\n",
    "                    new_surf_vars[var_name] = torch.cat([old_current, new_prediction], dim=1)\n",
    "            \n",
    "            # Similar for atmospheric variables\n",
    "            new_atmos_vars = {}\n",
    "            for var_name in pred_batch.atmos_vars.keys():\n",
    "                if var_name in current_batch.atmos_vars:\n",
    "                    old_current = current_batch.atmos_vars[var_name][:, -1:, :, :, :]\n",
    "                    new_prediction = pred_batch.atmos_vars[var_name]\n",
    "                    new_atmos_vars[var_name] = torch.cat([old_current, new_prediction], dim=1)\n",
    "            \n",
    "            # Create new batch for next iteration\n",
    "            current_batch = Batch(\n",
    "                surf_vars=new_surf_vars,\n",
    "                static_vars=current_batch.static_vars,  # Static vars don't change\n",
    "                atmos_vars=new_atmos_vars,\n",
    "                metadata=pred_batch.metadata\n",
    "            )\n",
    "        \n",
    "        print(f\"‚úì {pred_batch.metadata.time[0]}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generated {len(predictions)} weather predictions!\")\n",
    "    return predictions\n",
    "\n",
    "# Generate predictions\n",
    "try:\n",
    "    weather_predictions = generate_predictions(aurora_model, aurora_batch, num_steps=4)\n",
    "    \n",
    "    print(f\"\\nüìä Prediction Summary:\")\n",
    "    for i, pred in enumerate(weather_predictions):\n",
    "        pred_time = pred.metadata.time[0]\n",
    "        print(f\"   Step {i+1}: {pred_time.strftime('%Y-%m-%d %H:%M UTC')}\")\n",
    "        \n",
    "        # Show some statistics\n",
    "        if '2t' in pred.surf_vars:\n",
    "            temp_mean = pred.surf_vars['2t'].mean().item()\n",
    "            temp_min = pred.surf_vars['2t'].min().item()\n",
    "            temp_max = pred.surf_vars['2t'].max().item()\n",
    "            print(f\"            Temperature: {temp_mean:.1f}¬∞C (range: {temp_min:.1f}-{temp_max:.1f}¬∞C)\")\n",
    "        \n",
    "        if 'msl' in pred.surf_vars:\n",
    "            pressure_mean = pred.surf_vars['msl'].mean().item() / 100  # Convert to hPa\n",
    "            print(f\"            Pressure: {pressure_mean:.1f} hPa\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error generating predictions: {e}\")\n",
    "    weather_predictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Weather Predictions\n",
    "\n",
    "Let's create comprehensive visualizations of the Aurora weather predictions for Maharashtra, including:\n",
    "- Temperature evolution\n",
    "- Wind pattern changes\n",
    "- Pressure system movement\n",
    "- Comparison with initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-19T11:33:36.428255Z",
     "iopub.status.idle": "2025-06-19T11:33:36.429224Z",
     "shell.execute_reply": "2025-06-19T11:33:36.428983Z",
     "shell.execute_reply.started": "2025-06-19T11:33:36.428972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize weather predictions\n",
    "print(\"üìä Creating weather prediction visualizations...\")\n",
    "\n",
    "def extract_prediction_data(predictions):\n",
    "    \"\"\"Extract data from predictions for visualization\"\"\"\n",
    "    pred_data = []\n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        # Extract coordinates from metadata\n",
    "        lats = pred.metadata.lat.numpy() if hasattr(pred.metadata.lat, 'numpy') else pred.metadata.lat\n",
    "        lons = pred.metadata.lon.numpy() if hasattr(pred.metadata.lon, 'numpy') else pred.metadata.lon\n",
    "        \n",
    "        # Create coordinate meshgrid\n",
    "        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "        \n",
    "        # Extract variables\n",
    "        step_data = {\n",
    "            'step': i + 1,\n",
    "            'time': pred.metadata.time[0],\n",
    "            'latitude': lat_grid,\n",
    "            'longitude': lon_grid,\n",
    "        }\n",
    "        \n",
    "        # Extract surface variables\n",
    "        for var_name, tensor in pred.surf_vars.items():\n",
    "            # tensor shape: (b, t, h, w) - take the current time step\n",
    "            data = tensor[0, -1, :, :].numpy() if hasattr(tensor, 'numpy') else tensor[0, -1, :, :].detach().numpy()\n",
    "            step_data[var_name] = data\n",
    "        \n",
    "        pred_data.append(step_data)\n",
    "    \n",
    "    return pred_data\n",
    "\n",
    "# Extract prediction data\n",
    "if weather_predictions:\n",
    "    pred_data = extract_prediction_data(weather_predictions)\n",
    "    \n",
    "    print(f\"‚úÖ Extracted data for {len(pred_data)} prediction steps\")\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(24, 18))\n",
    "    \n",
    "    # Temperature evolution\n",
    "    print(\"   üå°Ô∏è  Creating temperature evolution plots...\")\n",
    "    for i, data in enumerate(pred_data):\n",
    "        ax = plt.subplot(3, 4, i + 1, projection=ccrs.PlateCarree())\n",
    "        ax.set_extent([72, 81, 15, 23], crs=ccrs.PlateCarree())\n",
    "        ax.add_feature(cfeature.COASTLINE, alpha=0.8)\n",
    "        ax.add_feature(cfeature.BORDERS, alpha=0.8)\n",
    "        ax.add_feature(cfeature.STATES, linestyle='--', alpha=0.5)\n",
    "        \n",
    "        if '2t' in data:\n",
    "            temp_data = data['2t'] - 273.15 if data['2t'].mean() > 100 else data['2t']  # Convert K to C if needed\n",
    "            \n",
    "            contour = ax.contourf(data['longitude'], data['latitude'], temp_data,\n",
    "                                levels=20, cmap='RdYlBu_r', transform=ccrs.PlateCarree(),\n",
    "                                extend='both')\n",
    "            \n",
    "            # Add wind vectors if available\n",
    "            if '10u' in data and '10v' in data:\n",
    "                # Subsample for cleaner arrows\n",
    "                skip = 2\n",
    "                ax.quiver(data['longitude'][::skip, ::skip], data['latitude'][::skip, ::skip],\n",
    "                         data['10u'][::skip, ::skip], data['10v'][::skip, ::skip],\n",
    "                         transform=ccrs.PlateCarree(), alpha=0.7, scale=50, width=0.003)\n",
    "        \n",
    "        ax.set_title(f'Step {data[\"step\"]}: {data[\"time\"].strftime(\"%Y-%m-%d %H:%M\")}\\nTemperature & Wind',\n",
    "                    fontsize=10)\n",
    "        ax.gridlines(draw_labels=True, alpha=0.3, linewidth=0.5)\n",
    "        \n",
    "        # Add colorbar for first plot\n",
    "        if i == 0 and '2t' in data:\n",
    "            plt.colorbar(contour, ax=ax, shrink=0.8, label='Temperature (¬∞C)')\n",
    "    \n",
    "    # Wind speed evolution\n",
    "    print(\"   üí® Creating wind speed evolution plots...\")\n",
    "    for i, data in enumerate(pred_data):\n",
    "        ax = plt.subplot(3, 4, i + 5, projection=ccrs.PlateCarree())\n",
    "        ax.set_extent([72, 81, 15, 23], crs=ccrs.PlateCarree())\n",
    "        ax.add_feature(cfeature.COASTLINE, alpha=0.8)\n",
    "        ax.add_feature(cfeature.BORDERS, alpha=0.8)\n",
    "        ax.add_feature(cfeature.STATES, linestyle='--', alpha=0.5)\n",
    "        \n",
    "        if '10u' in data and '10v' in data:\n",
    "            wind_speed = np.sqrt(data['10u']**2 + data['10v']**2)\n",
    "            \n",
    "            contour = ax.contourf(data['longitude'], data['latitude'], wind_speed,\n",
    "                                levels=15, cmap='viridis', transform=ccrs.PlateCarree(),\n",
    "                                extend='max')\n",
    "            \n",
    "            # Add streamlines\n",
    "            ax.streamplot(data['longitude'], data['latitude'],\n",
    "                         data['10u'], data['10v'],\n",
    "                         transform=ccrs.PlateCarree(), density=1, linewidth=0.8,\n",
    "                         color='white', alpha=0.6)\n",
    "        \n",
    "        ax.set_title(f'Step {data[\"step\"]}: Wind Speed & Direction', fontsize=10)\n",
    "        ax.gridlines(draw_labels=True, alpha=0.3, linewidth=0.5)\n",
    "        \n",
    "        # Add colorbar for first plot\n",
    "        if i == 0 and '10u' in data and '10v' in data:\n",
    "            plt.colorbar(contour, ax=ax, shrink=0.8, label='Wind Speed (m/s)')\n",
    "    \n",
    "    # Pressure evolution\n",
    "    print(\"   üåÄ Creating pressure evolution plots...\")\n",
    "    for i, data in enumerate(pred_data):\n",
    "        ax = plt.subplot(3, 4, i + 9, projection=ccrs.PlateCarree())\n",
    "        ax.set_extent([72, 81, 15, 23], crs=ccrs.PlateCarree())\n",
    "        ax.add_feature(cfeature.COASTLINE, alpha=0.8)\n",
    "        ax.add_feature(cfeature.BORDERS, alpha=0.8)\n",
    "        ax.add_feature(cfeature.STATES, linestyle='--', alpha=0.5)\n",
    "        \n",
    "        if 'msl' in data:\n",
    "            pressure_data = data['msl'] / 100  # Convert to hPa\n",
    "            \n",
    "            contour = ax.contour(data['longitude'], data['latitude'], pressure_data,\n",
    "                               levels=15, colors='black', linewidths=1,\n",
    "                               transform=ccrs.PlateCarree())\n",
    "            ax.clabel(contour, inline=True, fontsize=8, fmt='%d')\n",
    "            \n",
    "            # Fill contours for better visualization\n",
    "            contourf = ax.contourf(data['longitude'], data['latitude'], pressure_data,\n",
    "                                 levels=15, cmap='RdBu_r', alpha=0.6,\n",
    "                                 transform=ccrs.PlateCarree())\n",
    "        \n",
    "        ax.set_title(f'Step {data[\"step\"]}: Sea Level Pressure', fontsize=10)\n",
    "        ax.gridlines(draw_labels=True, alpha=0.3, linewidth=0.5)\n",
    "        \n",
    "        # Add colorbar for first plot\n",
    "        if i == 0 and 'msl' in data:\n",
    "            plt.colorbar(contourf, ax=ax, shrink=0.8, label='Pressure (hPa)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Microsoft Aurora Weather Predictions for Maharashtra, India\\n'\n",
    "                 f'Forecast Period: {pred_data[0][\"time\"].strftime(\"%Y-%m-%d %H:%M\")} to '\n",
    "                 f'{pred_data[-1][\"time\"].strftime(\"%Y-%m-%d %H:%M\")} UTC', \n",
    "                 fontsize=16, y=0.98)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No predictions available for visualization\")\n",
    "\n",
    "print(\"‚úÖ Weather prediction visualization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-19T11:33:36.431858Z",
     "iopub.status.idle": "2025-06-19T11:33:36.433266Z",
     "shell.execute_reply": "2025-06-19T11:33:36.433171Z",
     "shell.execute_reply.started": "2025-06-19T11:33:36.433161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create time series analysis of predictions\n",
    "print(\"üìà Creating time series analysis of weather predictions...\")\n",
    "\n",
    "if weather_predictions and pred_data:\n",
    "    # Extract regional averages for time series\n",
    "    times = [data['time'] for data in pred_data]\n",
    "    \n",
    "    # Calculate regional averages\n",
    "    temp_avg = []\n",
    "    pressure_avg = []\n",
    "    wind_speed_avg = []\n",
    "    \n",
    "    for data in pred_data:\n",
    "        if '2t' in data:\n",
    "            temp_data = data['2t'] - 273.15 if data['2t'].mean() > 100 else data['2t']\n",
    "            temp_avg.append(temp_data.mean())\n",
    "        \n",
    "        if 'msl' in data:\n",
    "            pressure_avg.append(data['msl'].mean() / 100)  # Convert to hPa\n",
    "        \n",
    "        if '10u' in data and '10v' in data:\n",
    "            wind_speed = np.sqrt(data['10u']**2 + data['10v']**2)\n",
    "            wind_speed_avg.append(wind_speed.mean())\n",
    "    \n",
    "    # Create time series plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Temperature time series\n",
    "    if temp_avg:\n",
    "        axes[0, 0].plot(times, temp_avg, 'r-o', linewidth=2, markersize=8, label='Average Temperature')\n",
    "        axes[0, 0].set_ylabel('Temperature (¬∞C)', fontsize=12)\n",
    "        axes[0, 0].set_title('Temperature Evolution Over Maharashtra', fontsize=14, fontweight='bold')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        axes[0, 0].legend()\n",
    "        \n",
    "        # Add temperature range\n",
    "        temp_min = [data['2t'].min() - 273.15 if data['2t'].mean() > 100 else data['2t'].min() for data in pred_data if '2t' in data]\n",
    "        temp_max = [data['2t'].max() - 273.15 if data['2t'].mean() > 100 else data['2t'].max() for data in pred_data if '2t' in data]\n",
    "        if temp_min and temp_max:\n",
    "            axes[0, 0].fill_between(times, temp_min, temp_max, alpha=0.3, color='red', label='Temperature Range')\n",
    "    \n",
    "    # Pressure time series\n",
    "    if pressure_avg:\n",
    "        axes[0, 1].plot(times, pressure_avg, 'b-o', linewidth=2, markersize=8, label='Average Pressure')\n",
    "        axes[0, 1].set_ylabel('Pressure (hPa)', fontsize=12)\n",
    "        axes[0, 1].set_title('Pressure Evolution Over Maharashtra', fontsize=14, fontweight='bold')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].legend()\n",
    "    \n",
    "    # Wind speed time series\n",
    "    if wind_speed_avg:\n",
    "        axes[1, 0].plot(times, wind_speed_avg, 'g-o', linewidth=2, markersize=8, label='Average Wind Speed')\n",
    "        axes[1, 0].set_ylabel('Wind Speed (m/s)', fontsize=12)\n",
    "        axes[1, 0].set_title('Wind Speed Evolution Over Maharashtra', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        axes[1, 0].legend()\n",
    "    \n",
    "    # Summary statistics\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Create summary text\n",
    "    summary_text = \"üå§Ô∏è WEATHER FORECAST SUMMARY FOR MAHARASHTRA\\n\\n\"\n",
    "    \n",
    "    if temp_avg:\n",
    "        temp_change = temp_avg[-1] - temp_avg[0]\n",
    "        summary_text += f\"üå°Ô∏è TEMPERATURE:\\n\"\n",
    "        summary_text += f\"   Initial: {temp_avg[0]:.1f}¬∞C\\n\"\n",
    "        summary_text += f\"   Final: {temp_avg[-1]:.1f}¬∞C\\n\"\n",
    "        summary_text += f\"   Change: {temp_change:+.1f}¬∞C\\n\\n\"\n",
    "    \n",
    "    if pressure_avg:\n",
    "        pressure_change = pressure_avg[-1] - pressure_avg[0]\n",
    "        summary_text += f\"üåÄ PRESSURE:\\n\"\n",
    "        summary_text += f\"   Initial: {pressure_avg[0]:.1f} hPa\\n\"\n",
    "        summary_text += f\"   Final: {pressure_avg[-1]:.1f} hPa\\n\"\n",
    "        summary_text += f\"   Change: {pressure_change:+.1f} hPa\\n\\n\"\n",
    "    \n",
    "    if wind_speed_avg:\n",
    "        wind_change = wind_speed_avg[-1] - wind_speed_avg[0]\n",
    "        summary_text += f\"üí® WIND SPEED:\\n\"\n",
    "        summary_text += f\"   Initial: {wind_speed_avg[0]:.1f} m/s\\n\"\n",
    "        summary_text += f\"   Final: {wind_speed_avg[-1]:.1f} m/s\\n\"\n",
    "        summary_text += f\"   Change: {wind_change:+.1f} m/s\\n\\n\"\n",
    "    \n",
    "    summary_text += f\"üìÖ FORECAST PERIOD:\\n\"\n",
    "    summary_text += f\"   From: {times[0].strftime('%Y-%m-%d %H:%M UTC')}\\n\"\n",
    "    summary_text += f\"   To: {times[-1].strftime('%Y-%m-%d %H:%M UTC')}\\n\"\n",
    "    summary_text += f\"   Duration: {len(times)} √ó 6-hour steps\\n\\n\"\n",
    "    \n",
    "    summary_text += f\"ü§ñ MODEL: Microsoft Aurora\\n\"\n",
    "    summary_text += f\"üìä GRID POINTS: ~{pred_data[0]['latitude'].size}\\n\"\n",
    "    summary_text += f\"üó∫Ô∏è REGION: Maharashtra, India\"\n",
    "    \n",
    "    axes[1, 1].text(0.05, 0.95, summary_text, transform=axes[1, 1].transAxes,\n",
    "                   fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    # Format x-axis labels\n",
    "    for ax in axes.flat:\n",
    "        if ax != axes[1, 1]:  # Skip the summary panel\n",
    "            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Weather Prediction Time Series Analysis\\nMaharashtra, India - Microsoft Aurora Model',\n",
    "                fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Time series analysis completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No prediction data available for time series analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Performance Analysis\n",
    "\n",
    "Let's analyze the Aurora model's predictions and provide insights about the weather forecast for Maharashtra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-19T11:33:36.436340Z",
     "iopub.status.idle": "2025-06-19T11:33:36.436753Z",
     "shell.execute_reply": "2025-06-19T11:33:36.436678Z",
     "shell.execute_reply.started": "2025-06-19T11:33:36.436671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze model performance and provide weather insights\n",
    "print(\"üîç Analyzing Aurora model predictions and weather patterns...\")\n",
    "\n",
    "def analyze_weather_patterns(pred_data):\n",
    "    \"\"\"Analyze weather patterns from predictions\"\"\"\n",
    "    analysis = {\n",
    "        'temporal_trends': {},\n",
    "        'spatial_patterns': {},\n",
    "        'meteorological_insights': {},\n",
    "        'extreme_events': {}\n",
    "    }\n",
    "    \n",
    "    if not pred_data:\n",
    "        return analysis\n",
    "    \n",
    "    # Temporal trends analysis\n",
    "    print(\"   üìà Analyzing temporal trends...\")\n",
    "    \n",
    "    times = [data['time'] for data in pred_data]\n",
    "    \n",
    "    if '2t' in pred_data[0]:\n",
    "        temps = [data['2t'].mean() for data in pred_data]\n",
    "        temps = [t - 273.15 if t > 100 else t for t in temps]  # Convert K to C if needed\n",
    "        \n",
    "        analysis['temporal_trends']['temperature'] = {\n",
    "            'initial': temps[0],\n",
    "            'final': temps[-1],\n",
    "            'change': temps[-1] - temps[0],\n",
    "            'trend': 'warming' if temps[-1] > temps[0] else 'cooling',\n",
    "            'variability': np.std(temps)\n",
    "        }\n",
    "    \n",
    "    if 'msl' in pred_data[0]:\n",
    "        pressures = [data['msl'].mean() / 100 for data in pred_data]  # Convert to hPa\n",
    "        \n",
    "        analysis['temporal_trends']['pressure'] = {\n",
    "            'initial': pressures[0],\n",
    "            'final': pressures[-1],\n",
    "            'change': pressures[-1] - pressures[0],\n",
    "            'trend': 'rising' if pressures[-1] > pressures[0] else 'falling',\n",
    "            'variability': np.std(pressures)\n",
    "        }\n",
    "    \n",
    "    # Spatial patterns analysis\n",
    "    print(\"   üó∫Ô∏è  Analyzing spatial patterns...\")\n",
    "    \n",
    "    for i, data in enumerate(pred_data):\n",
    "        if '2t' in data:\n",
    "            temp_data = data['2t'] - 273.15 if data['2t'].mean() > 100 else data['2t']\n",
    "            \n",
    "            analysis['spatial_patterns'][f'step_{i+1}'] = {\n",
    "                'temp_gradient': {\n",
    "                    'north_south': temp_data[0, :].mean() - temp_data[-1, :].mean(),\n",
    "                    'east_west': temp_data[:, -1].mean() - temp_data[:, 0].mean(),\n",
    "                    'max_temp_location': np.unravel_index(temp_data.argmax(), temp_data.shape),\n",
    "                    'min_temp_location': np.unravel_index(temp_data.argmin(), temp_data.shape)\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        if '10u' in data and '10v' in data:\n",
    "            wind_speed = np.sqrt(data['10u']**2 + data['10v']**2)\n",
    "            wind_direction = np.arctan2(data['10v'], data['10u']) * 180 / np.pi\n",
    "            \n",
    "            if f'step_{i+1}' not in analysis['spatial_patterns']:\n",
    "                analysis['spatial_patterns'][f'step_{i+1}'] = {}\n",
    "            \n",
    "            analysis['spatial_patterns'][f'step_{i+1}']['wind'] = {\n",
    "                'max_wind_speed': wind_speed.max(),\n",
    "                'avg_wind_speed': wind_speed.mean(),\n",
    "                'dominant_direction': np.median(wind_direction),\n",
    "                'max_wind_location': np.unravel_index(wind_speed.argmax(), wind_speed.shape)\n",
    "            }\n",
    "    \n",
    "    # Meteorological insights\n",
    "    print(\"   üå§Ô∏è  Generating meteorological insights...\")\n",
    "    \n",
    "    insights = []\n",
    "    \n",
    "    if 'temperature' in analysis['temporal_trends']:\n",
    "        temp_trend = analysis['temporal_trends']['temperature']\n",
    "        if abs(temp_trend['change']) > 2:\n",
    "            insights.append(f\"Significant temperature {temp_trend['trend']} of {temp_trend['change']:.1f}¬∞C expected\")\n",
    "        \n",
    "        if temp_trend['initial'] > 35:\n",
    "            insights.append(\"Hot weather conditions with temperatures above 35¬∞C\")\n",
    "        elif temp_trend['initial'] < 15:\n",
    "            insights.append(\"Cool weather conditions with temperatures below 15¬∞C\")\n",
    "    \n",
    "    if 'pressure' in analysis['temporal_trends']:\n",
    "        pressure_trend = analysis['temporal_trends']['pressure']\n",
    "        if abs(pressure_trend['change']) > 5:\n",
    "            insights.append(f\"Notable pressure {pressure_trend['trend']} of {pressure_trend['change']:.1f} hPa\")\n",
    "        \n",
    "        if pressure_trend['initial'] < 1010:\n",
    "            insights.append(\"Low pressure system present - possible weather disturbance\")\n",
    "        elif pressure_trend['initial'] > 1020:\n",
    "            insights.append(\"High pressure system - generally stable weather expected\")\n",
    "    \n",
    "    analysis['meteorological_insights']['summary'] = insights\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Perform analysis\n",
    "if weather_predictions and pred_data:\n",
    "    weather_analysis = analyze_weather_patterns(pred_data)\n",
    "    \n",
    "    print(\"\\nüìä WEATHER ANALYSIS RESULTS:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display temporal trends\n",
    "    if weather_analysis['temporal_trends']:\n",
    "        print(\"\\nüïí TEMPORAL TRENDS:\")\n",
    "        \n",
    "        if 'temperature' in weather_analysis['temporal_trends']:\n",
    "            temp = weather_analysis['temporal_trends']['temperature']\n",
    "            print(f\"   üå°Ô∏è  Temperature: {temp['initial']:.1f}¬∞C ‚Üí {temp['final']:.1f}¬∞C ({temp['change']:+.1f}¬∞C, {temp['trend']})\")\n",
    "            print(f\"       Variability: ¬±{temp['variability']:.1f}¬∞C\")\n",
    "        \n",
    "        if 'pressure' in weather_analysis['temporal_trends']:\n",
    "            pres = weather_analysis['temporal_trends']['pressure']\n",
    "            print(f\"   üåÄ Pressure: {pres['initial']:.1f} hPa ‚Üí {pres['final']:.1f} hPa ({pres['change']:+.1f} hPa, {pres['trend']})\")\n",
    "            print(f\"       Variability: ¬±{pres['variability']:.1f} hPa\")\n",
    "    \n",
    "    # Display meteorological insights\n",
    "    if weather_analysis['meteorological_insights']['summary']:\n",
    "        print(\"\\nüå§Ô∏è  METEOROLOGICAL INSIGHTS:\")\n",
    "        for insight in weather_analysis['meteorological_insights']['summary']:\n",
    "            print(f\"   ‚Ä¢ {insight}\")\n",
    "    \n",
    "    # Weather forecast summary\n",
    "    print(\"\\nüìã FORECAST SUMMARY FOR MAHARASHTRA:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if 'temperature' in weather_analysis['temporal_trends']:\n",
    "        temp_trend = weather_analysis['temporal_trends']['temperature']\n",
    "        if temp_trend['change'] > 1:\n",
    "            print(f\"üî• Warming trend expected (+{temp_trend['change']:.1f}¬∞C)\")\n",
    "        elif temp_trend['change'] < -1:\n",
    "            print(f\"‚ùÑÔ∏è  Cooling trend expected ({temp_trend['change']:.1f}¬∞C)\")\n",
    "        else:\n",
    "            print(f\"üå°Ô∏è  Stable temperatures (~{temp_trend['initial']:.1f}¬∞C)\")\n",
    "    \n",
    "    if 'pressure' in weather_analysis['temporal_trends']:\n",
    "        pres_trend = weather_analysis['temporal_trends']['pressure']\n",
    "        if pres_trend['change'] > 2:\n",
    "            print(f\"üìà Rising pressure - improving weather\")\n",
    "        elif pres_trend['change'] < -2:\n",
    "            print(f\"üìâ Falling pressure - possible weather changes\")\n",
    "        else:\n",
    "            print(f\"‚öñÔ∏è  Stable pressure conditions\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Forecast valid for: {len(pred_data)} √ó 6-hour periods\")\n",
    "    print(f\"ü§ñ Generated by: Microsoft Aurora Model\")\n",
    "    print(f\"üìç Region: Maharashtra, India\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No prediction data available for analysis\")\n",
    "\n",
    "print(\"\\n‚úÖ Weather analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results and Summary\n",
    "\n",
    "Finally, let's export our results and create a comprehensive summary of the weather prediction workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-19T11:33:36.439426Z",
     "iopub.status.idle": "2025-06-19T11:33:36.440049Z",
     "shell.execute_reply": "2025-06-19T11:33:36.439939Z",
     "shell.execute_reply.started": "2025-06-19T11:33:36.439933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Export results and create summary\n",
    "print(\"üíæ Exporting results and creating workflow summary...\")\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory\n",
    "results_dir = f\"../results_{config['request_id']}\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Export prediction data\n",
    "if weather_predictions and pred_data:\n",
    "    print(\"   üìä Exporting prediction data...\")\n",
    "    \n",
    "    # Convert predictions to exportable format\n",
    "    export_data = []\n",
    "    \n",
    "    for data in pred_data:\n",
    "        # Convert numpy arrays to lists for JSON serialization\n",
    "        export_step = {\n",
    "            'step': data['step'],\n",
    "            'time': data['time'].isoformat(),\n",
    "            'variables': {}\n",
    "        }\n",
    "        \n",
    "        # Extract grid data\n",
    "        lats = data['latitude']\n",
    "        lons = data['longitude']\n",
    "        \n",
    "        for var_name in ['2t', '10u', '10v', 'msl']:\n",
    "            if var_name in data:\n",
    "                var_data = data[var_name]\n",
    "                # Convert to grid points\n",
    "                points = []\n",
    "                for i in range(var_data.shape[0]):\n",
    "                    for j in range(var_data.shape[1]):\n",
    "                        points.append({\n",
    "                            'latitude': float(lats[i, j]),\n",
    "                            'longitude': float(lons[i, j]),\n",
    "                            'value': float(var_data[i, j])\n",
    "                        })\n",
    "                export_step['variables'][var_name] = points\n",
    "        \n",
    "        export_data.append(export_step)\n",
    "    \n",
    "    # Save predictions as JSON\n",
    "    predictions_file = os.path.join(results_dir, 'aurora_predictions.json')\n",
    "    with open(predictions_file, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(f\"   ‚úÖ Predictions saved to: {predictions_file}\")\n",
    "\n",
    "# Export weather analysis\n",
    "if 'weather_analysis' in locals():\n",
    "    print(\"   üìà Exporting weather analysis...\")\n",
    "    \n",
    "    # Convert analysis to JSON-serializable format\n",
    "    analysis_export = {}\n",
    "    for key, value in weather_analysis.items():\n",
    "        if isinstance(value, dict):\n",
    "            analysis_export[key] = {}\n",
    "            for subkey, subvalue in value.items():\n",
    "                if isinstance(subvalue, (int, float, str, list)):\n",
    "                    analysis_export[key][subkey] = subvalue\n",
    "                elif isinstance(subvalue, dict):\n",
    "                    analysis_export[key][subkey] = {k: v for k, v in subvalue.items() \n",
    "                                                  if isinstance(v, (int, float, str, list))}\n",
    "    \n",
    "    analysis_file = os.path.join(results_dir, 'weather_analysis.json')\n",
    "    with open(analysis_file, 'w') as f:\n",
    "        json.dump(analysis_export, f, indent=2)\n",
    "    \n",
    "    print(f\"   ‚úÖ Analysis saved to: {analysis_file}\")\n",
    "\n",
    "# Create comprehensive summary report\n",
    "print(\"   üìù Creating summary report...\")\n",
    "\n",
    "summary_report = f\"\"\"\n",
    "# ERA5 Data Processing and Microsoft Aurora Weather Prediction Report\n",
    "**Region:** Maharashtra, India  \n",
    "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}  \n",
    "**Request ID:** {config['request_id']}  \n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This report presents the results of weather prediction for Maharashtra, India using:\n",
    "- **Data Source:** ERA5 reanalysis data from ECMWF\n",
    "- **Processing Tool:** eranest Python package\n",
    "- **Prediction Model:** Microsoft Aurora AI weather model\n",
    "- **Forecast Period:** {config['start_date'].strftime('%Y-%m-%d')} to {config['end_date'].strftime('%Y-%m-%d')}\n",
    "\n",
    "## Data Processing Summary\n",
    "\n",
    "### ERA5 Data Retrieved:\n",
    "- **Surface Variables:** {', '.join(config['surface_variables'])}\n",
    "- **Atmospheric Variables:** {', '.join(config['atmospheric_variables'])}\n",
    "- **Static Variables:** {', '.join(config['static_variables'])}\n",
    "- **Pressure Levels:** {', '.join(config['pressure_levels'])} hPa\n",
    "- **Spatial Resolution:** {config['resolution']}¬∞ (~{config['resolution']*111:.0f}km)\n",
    "- **Temporal Resolution:** {config['frequency']}\n",
    "\n",
    "### Geographic Coverage:\n",
    "- **State:** Maharashtra, India\n",
    "- **Approximate Bounds:** 15.6¬∞N to 22.0¬∞N, 72.6¬∞E to 80.9¬∞E\n",
    "- **Grid Points:** ~{pred_data[0]['latitude'].size if 'pred_data' in locals() and pred_data else 'N/A'}\n",
    "\n",
    "## Weather Prediction Results\n",
    "\"\"\"\n",
    "\n",
    "if 'weather_analysis' in locals() and weather_analysis['temporal_trends']:\n",
    "    if 'temperature' in weather_analysis['temporal_trends']:\n",
    "        temp = weather_analysis['temporal_trends']['temperature']\n",
    "        summary_report += f\"\"\"\n",
    "### Temperature Forecast:\n",
    "- **Initial Temperature:** {temp['initial']:.1f}¬∞C\n",
    "- **Final Temperature:** {temp['final']:.1f}¬∞C\n",
    "- **Temperature Trend:** {temp['trend'].capitalize()} ({temp['change']:+.1f}¬∞C)\n",
    "- **Temperature Variability:** ¬±{temp['variability']:.1f}¬∞C\n",
    "\"\"\"\n",
    "    \n",
    "    if 'pressure' in weather_analysis['temporal_trends']:\n",
    "        pres = weather_analysis['temporal_trends']['pressure']\n",
    "        summary_report += f\"\"\"\n",
    "### Pressure Forecast:\n",
    "- **Initial Pressure:** {pres['initial']:.1f} hPa\n",
    "- **Final Pressure:** {pres['final']:.1f} hPa\n",
    "- **Pressure Trend:** {pres['trend'].capitalize()} ({pres['change']:+.1f} hPa)\n",
    "- **Pressure Variability:** ¬±{pres['variability']:.1f} hPa\n",
    "\"\"\"\n",
    "    \n",
    "    if weather_analysis['meteorological_insights']['summary']:\n",
    "        summary_report += f\"\"\"\n",
    "### Key Meteorological Insights:\n",
    "\"\"\"\n",
    "        for insight in weather_analysis['meteorological_insights']['summary']:\n",
    "            summary_report += f\"- {insight}\\n\"\n",
    "\n",
    "summary_report += f\"\"\"\n",
    "\n",
    "## Technical Details\n",
    "\n",
    "### Model Configuration:\n",
    "- **Aurora Model Type:** {'Real' if is_real_model else 'Mock (Demonstration)'}\n",
    "- **Prediction Steps:** {len(pred_data) if 'pred_data' in locals() and pred_data else 'N/A'}\n",
    "- **Time Step:** 6 hours\n",
    "- **Total Forecast Period:** {len(pred_data) * 6 if 'pred_data' in locals() and pred_data else 'N/A'} hours\n",
    "\n",
    "### Data Quality:\n",
    "- **ERA5 Data Status:** {'‚úÖ Successfully Downloaded' if 'era5_data' in locals() else '‚ö†Ô∏è Mock Data Used'}\n",
    "- **Aurora Processing:** {'‚úÖ Completed' if 'aurora_batch' in locals() else '‚ùå Failed'}\n",
    "- **Predictions Generated:** {'‚úÖ Yes' if 'weather_predictions' in locals() and weather_predictions else '‚ùå No'}\n",
    "\n",
    "## Files Generated:\n",
    "\n",
    "1. **aurora_predictions.json** - Detailed prediction data\n",
    "2. **weather_analysis.json** - Statistical analysis results\n",
    "3. **summary_report.md** - This comprehensive report\n",
    "\n",
    "## Usage Notes:\n",
    "\n",
    "This demonstration showcases the complete workflow from ERA5 data retrieval to Aurora predictions. \n",
    "For operational use:\n",
    "\n",
    "1. Ensure CDS API credentials are properly configured\n",
    "2. Install Microsoft Aurora from the official repository\n",
    "3. Consider computational resources for larger domains\n",
    "4. Validate predictions against observations for accuracy assessment\n",
    "\n",
    "---\n",
    "**Generated by:** eranest package v0.1.0  \n",
    "**Aurora Model:** Microsoft Aurora AI Weather Prediction  \n",
    "**Data Source:** ECMWF ERA5 Reanalysis  \n",
    "\"\"\"\n",
    "\n",
    "# Save summary report\n",
    "summary_file = os.path.join(results_dir, 'summary_report.md')\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(f\"   ‚úÖ Summary report saved to: {summary_file}\")\n",
    "\n",
    "# Display final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ WORKFLOW COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìÅ Results Directory: {results_dir}\")\n",
    "print(f\"üìä Predictions Generated: {len(pred_data) if 'pred_data' in locals() and pred_data else 0} time steps\")\n",
    "print(f\"üåç Region Covered: Maharashtra, India\")\n",
    "print(f\"ü§ñ Model Used: Microsoft Aurora ({'Real' if is_real_model else 'Mock Demo'})\")\n",
    "print(f\"üìà Analysis Completed: {'‚úÖ' if 'weather_analysis' in locals() else '‚ùå'}\")\n",
    "print(f\"üíæ Files Exported: {'‚úÖ' if os.path.exists(summary_file) else '‚ùå'}\")\n",
    "\n",
    "print(\"\\nüîó Next Steps:\")\n",
    "print(\"   1. Review the generated visualizations above\")\n",
    "print(\"   2. Check the exported files in the results directory\")\n",
    "print(\"   3. Validate predictions against observations (if available)\")\n",
    "print(\"   4. Consider extending the forecast period or domain\")\n",
    "print(\"   5. Explore different meteorological variables\")\n",
    "\n",
    "print(f\"\\nüìö For more information about eranest: https://github.com/JaggeryArray/eranest\")\n",
    "print(f\"ü§ñ For Microsoft Aurora: https://github.com/microsoft/aurora\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aurora]",
   "language": "python",
   "name": "conda-env-aurora-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
